---
title: "National Borders (Still) Matter"
subtitle: ""
author: "David Sneddon"
institute: "Old Dominion University"
format: 
  html:
    theme: lux # Check here for more themes: https://quarto.org/docs/output-formats/html-themes.html
    code-tools: true
    code-fold: true
    code-summary: "Code"
    code-copy: hover
    link-external-newwindow: true
    tbl-cap-location: top
    fig-cap-location: bottom

self-contained: true
editor: source
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
# DO NOT EDIT THIS

knitr::opts_chunk$set(fig.align = 'center')
knitr::opts_chunk$set(out.width = '90%')
knitr::opts_chunk$set(results = 'hold')
knitr::opts_chunk$set(fig.show = 'hold')
knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
par(mar = c(4.1, 4.1, 1.1, 4.1))

hooks = knitr::knit_hooks$get()
hook_foldable = function(type) {
  force(type)
  function(x, options) {
    res = hooks[[type]](x, options)
    
    if (is.na(as.logical(options[[paste0("fold.", type)]]))) {
      
      res
    } else if (isFALSE(as.logical(options[[paste0("fold.", type)]]))){
      
      # return(res)
      
      paste0(
      "<details open><summary>", gsub("^p", "P", gsub("^o", "O", type)), "</summary>\n\n",
      res,
      "\n\n</details>"
      )
    } else {
      
      paste0(
      "<details><summary>", gsub("^p", "P", gsub("^o", "O", type)), "</summary>\n\n",
      res,
      "\n\n</details>"
      )
    }
  }
}

knitr::knit_hooks$set(
  output = hook_foldable("output"),
  plot = hook_foldable("plot")
)
knitr::opts_chunk$set(fold.output=TRUE)
knitr::opts_chunk$set(fold.plot=TRUE)

Q <- 0
```

# Introduction

The gravity model of international trade. A relatively intuitive and straightforward understanding of international trade. At it's most basic level, trade between two entities will increase with the size of their economies and decrease with their distance from each other. It is so intuitive that it is sometimes called the naïve gravity model. [@RN66]\

$$
X_{ij}=\beta_0Y^{\beta_{1}}_{i}Y^{\beta_{2}}_{j}dist^{\beta_{3}}_{ij}\varepsilon_{ij}
$$

Or:

$$
ln(X_{ij}) = \beta_0 + \beta_1ln(Y_i)+\beta_2ln(Y_j)+\beta_3ln(dist_{ij})+ln(\varepsilon_{ij})
$$

> "Where $X_{ij}$ is is bilateral trade between exporting country $i$ and importing country $j$, $Y_i(Y_j)$ is the gross domestic product in country $i(j)$ and $dist_{ij}$ is the bilateral distance between country $i$ and $j$. $\varepsilon_{ij}$ is typically assumed to be a log-normally distributed error term."
> [@RN66]\




I will attempt to recreate, with some modifications, the work done by John McCallum "National Borders Matter: Canada-U.S. Regional Trade Patterns" [@RN68]. McCallum's article published one year after the North American Free Trade Agreement (NAFTA) came into effect. However his analysis uses data from 1988, before NAFTA came into effect.\

The results of McCallum's analysis indicated that the international border significantly diluted the effects of the gravity model. However, given that NAFTA had not yet come into effect, this is intuitive. I hope to assess the effect of NAFTA by replicating McCallum's analysis for 2019 data, the last full year that NAFTA was in effect. This year also is the last full year before significant impacts of the COVID-19 pandemic were felt in North America.\

As NAFTA was designed to remove trade barriers in North America, the intuitive expectation is that the effect of the international border between Canada and the United States will be reduced, and the its effect on the naïve gravity model will be reduced.

In @RN68 the implied null hypothesis is that there is no statistically significant effect of the international border. This paper will test McCallum's alternative hypothesis that the effect of NAFTA would be muted. As @RN68 did not indicate an alpha, I will test with an $\alpha=0.05$.

# Literature Review

This paper aims to be an only slightly modified recreation of McCallum's work in principle. His paper forms the basis of the project. While intuition may suggest that the removal of trade barriers combined with the historically porous US-Canada border would quickly see a muted effect of the international border, McCallum believed that the effects would be modest and/or gradual. [@RN68] 

It is clear that international trade has increased significantly, owing to decreased transport costs and a general trend of lower tariffs. [@lavallee] Nevertheless, there are other trade barriers aside from tariffs such as differences in preferences, institutions, currency differences, etc. [@anderson]

The literature suggests that while the gravity model overall tends to hold, ceteris paribus, "free trade" is but one of many factors influencing trade flows across international borders.

# Data

There is a wealth of data available from the [Canadian government](https://www.statcan.gc.ca/en/start). This includes interprovincial trade amongst the Canadian provinces and even international trade between Canadian provinces [@statcan_trade_data] and US States in addition to provinicial GDP data. Much of the US data is available from the US Census bureau, including state GDP and population.\

Geographic data for Canada was more difficult to come by, as I diverged from the original work done by McCallum by using population centroids as opposed to distance to principal cities. The US population centers were available from the Census bureau, however the Canadian counterparts were not. I ended up using ChatGPT to calculate these centroids (noted in the code). Summary statistics for the data to be used in the model are listed below both with and without a logarithmic transformation.\

# Code Walkthrough

This project is being compiled using [Quarto](https://quarto.org) in [RStudio](https://posit.co/downloads/). Not only does Quarto allow for professional and polished looking content; Quarto, RStudio, and [R](https://www.r-project.org/) [@rcite] are "free". There is a learning curve, so opportunity costs will apply. Another advantage of Quarto is the ability to embed and share code chunks in the final product. To that end: I will walk through the processes, step by step.

## Libraries and Options

These are the various libraries used throughout the project.

```{r}
library(geosphere)
library(utf8)
library(bea.R)
library(censusapi)
library(ggplot2)
library(modelsummary)
library(fixest)
options("modelsummary_factory_default" = "kableExtra")
options(scipen = 999)
```

`bea.R` [@bea.r]\
`censusapi` [@censusapi]\
`fixest` [@fixest]\
`geosphere` [@geosphere]\
`ggplot2` [@ggplot]\
`modelsummary` [@modelsummary]\
`utf8` [@utf8]\

## Data Imports and Data Cleaning

US State and FIPS Codes [@us_census_state_codes]


```{r}
#US DATA
usfips <- read.csv("https://www2.census.gov/geo/docs/reference/state.txt",
                   sep = "|")
usfips <- usfips[c(1, 2)]
colnames(usfips) <- c("STATE", "state")

```
Canadian Import and Export Data [@statcan_trade_data]
```{r}
##CANADIAN DATA
can_exports <- read.csv("https://www150.statcan.gc.ca/t1/tbl1/en/dtl!downloadDbLoadingData.action?pid=1210010101&latestN=0&startDate=20190101&endDate=20190101&csvLocale=en&selectedMembers=%5B%5B2%2C3%2C4%2C5%2C6%2C7%2C8%2C9%2C10%2C11%2C12%2C13%2C14%5D%2C%5B4%2C5%2C6%2C7%2C8%2C9%2C10%2C11%2C12%2C13%2C14%2C15%2C16%5D%2C%5B2%5D%5D&checkedLevels=")
can_exports <- can_exports[,c(2, 4, 5, 12)]
can_imports <- read.csv("ODPFN022_201912N.csv")
```
Geographic Data 
U.S. State Population Centers retrieved from @us_census_cenpop2020 and Canadian provincial population centers calculated with @chatgpt_calculation.
```{r}
##GEOGRAPHIC DATA
###Centers of Population
st_lat_long <- read.csv("st_pop_center.csv") #From Census.gov - 2020
canprov <- read.csv("canprovcenter.csv") #Calculated with ChatGPT - 2021
st_abbr <- read.csv("st_abbr.csv")
```
Distance calculations using great circles and the Haversine formula via geosphere::distHaversine() [@geosphere].
```{r}
#DISTANCE CALCULATIONS
geodata <- as.data.frame(rbind(as.matrix(st_lat_long),
                               as.matrix(canprov)))
geoframe <- data.frame(matrix(0, nrow(geodata)^2, 3))
colnames(geoframe) <- c("from", "to", "km")
c <- 1
for (i in geodata[,1]){
  for (w in geodata[,1]){
    
    lat_a <- as.numeric(geodata[geodata$state==i,2])
    lat_b <- as.numeric(geodata[geodata$state==w,2])
    lon_a <- as.numeric(geodata[geodata$state==i,3])
    lon_b <- as.numeric(geodata[geodata$state==w,3])
    geoframe[c,1] <- i
    geoframe[c,2] <- w
    geoframe[c,3] <- as.numeric(distHaversine(c(lon_a, lat_a),
                                              c(lon_b, lat_b)))/1000
    c <- c+1
  }
}
geoframe["fttag"] <- paste0(geoframe$from,geoframe$to)
geoframe <- geoframe[,c(3, 4)]

```
US State and Provincial Abbreviations
```{r}
#DATAFRAME FOR US STATE AND PROVINCIAL ABBREVIATIONS FOR UNIFORMITY
#NEEDED FOR MERGING
prov_abr <- data.frame(GEO = unique(can_exports$GEO))
prov_abr["from"] <- c("NL", "PE", "NS", "NB", "QC", "ON", "MB", "SK", "AB", 
                      "BC", "YT", "NT", "NU")
provto_abr <- prov_abr
provto_abr$GEO <- paste("To", prov_abr$GEO)
colnames(provto_abr) <- c("To_GEO","to")
colnames(can_exports)[2] <- "To_GEO"
```
Formatting of Canadian exports data frame for merging.
```{r}
#FORMAT can_exports  FOR MERGING
can_exports <- merge(can_exports, prov_abr, by="GEO")
can_exports <- merge(can_exports, provto_abr, by="To_GEO")
rm(provto_abr)
can_exports["value"] <- can_exports$VALUE*1000
can_exports <- can_exports[,-(1:4)]
can_exports["fttag"] <- paste0(can_exports$from,can_exports$to)
can_exports["intra"] <- -1
for (i in 1:nrow(can_exports)){
  if(can_exports$from[i]==can_exports$to[i]){
    can_exports$intra[i] <- 1
  }else
    can_exports$intra[i] <- 0
}
can_exports <- can_exports[can_exports$intra == 0,]
can_exports$intra <- NULL
tmp <- can_exports
can_exports <- tmp[,c(2,1,3,4)]
rm(tmp)
can_exports["domestic"] <- 1
```
Aggregate and condense can_imports data frame.
```{r}
###AGGREGATE AND CONDENSE CAN_IMPORTS DATAFRAME

can_imports <- can_imports[can_imports$Country.Pays=="US",]
colnames(can_imports) <- c("YearMonth", 
                           "HS2", 
                           "Country", 
                           "Province", 
                           "State", 
                           "Value")
can_imports <- aggregate(can_imports$Value
                         ~ can_imports$Country
                         + can_imports$Province
                         + can_imports$State,
                         FUN = sum)
for (i in 1:nrow(can_imports)){
  for (u in 1:3){
    can_imports[i,u] <- as_utf8(can_imports[i,u])
  }
}
can_imports <- can_imports[,c(2, 3, 4)]
colnames(can_imports) <- c("to", "from", "value")
can_imports["fttag"] <- paste0(can_imports$from,can_imports$to)
can_imports["domestic"] <- 0
```
Import Canadian [@statcan_gdp] and US GDP Data [@bea_sagdp1_2019].
```{r}
###CANADIAN GDP
can_gdp <- read.csv("https://www150.statcan.gc.ca/t1/tbl1/en/dtl!downloadDbLoadingData-nonTraduit.action?pid=3610040201&latestN=0&startDate=20190101&endDate=20190101&csvLocale=en&selectedMembers=%5B%5B1%2C2%2C3%2C4%2C5%2C6%2C7%2C8%2C9%2C10%2C11%2C12%2C13%5D%2C%5B1%5D%2C%5B1%5D%5D&checkedLevels=")
can_gdp <- can_gdp[,c("GEO","VALUE")]
can_gdp <- merge(can_gdp, prov_abr, by="GEO")
cagdp_f <- data.frame(from=can_gdp$from,
                      from_gdp=can_gdp$VALUE)
cagdp_t <- data.frame(to=can_gdp$from,
                      to_gdp=can_gdp$VALUE)

##US GDP
bkey <- "EB73777D-FF2C-43F1-A94A-E1BFFBA2744D"

userSpecList <- list('UserID' = bkey,
                     'Method' = 'GetData',
                     'datasetname' = 'Regional',
                     'GeoFips' = 'STATE',
                     'LineCode' = '3',
                     'TableName' = 'SAGDP1',
                     'Year' = '2019')
us_gdp <- beaGet(userSpecList)
us_gdp <- us_gdp[-1,]
us_gdp <- us_gdp[-(52:59),]
us_gdp <- us_gdp[,c(3, 6)]
exch_usca <- 1.3269 #USD TO CAD 2019 https://www.bankofcanada.ca/rates/exchange/annual-average-exchange-rates/
us_gdp <- merge(us_gdp, st_abbr, by="GeoName")
usgdp_f <- data.frame(from=us_gdp$State,
                      from_gdp=as.numeric(us_gdp$`DataValue_2019`)*exch_usca)
usgdp_t <- data.frame(to=us_gdp$State,
                      to_gdp=as.numeric(us_gdp$`DataValue_2019`)*exch_usca)
rm(us_gdp, exch_usca)
#MERGE BOTH COUNTRIES GDPs
gdp_f <- rbind(cagdp_f,usgdp_f)
rm(cagdp_f, usgdp_f)
gdp_t <- rbind(cagdp_t,usgdp_t)
rm(cagdp_t, usgdp_t)
```
Import U.S. population data from @census_p1_001n_2020 and Canadian population data from @statcan_population_dwelling_counts.
```{r}
##POPULATION
###US
st_pop <- getCensus(
  name = "dec/dhc",
  vars = "P1_001N",
  region = "state:*",
  vintage = 2020
)
st_pop$state <- as.numeric(st_pop$state)
colnames(st_pop) <- c("STATE", "pop")
st_pop <- merge(st_pop, usfips, by="STATE")
st_pop <- st_pop[,c(3, 2)]
st_pop_from <- data.frame(st_pop$state, st_pop$pop)
st_pop_to <- data.frame(st_pop$state, st_pop$pop)
colnames(st_pop_from) <- c("from","from_pop")
colnames(st_pop_to) <- c("to","to_pop")

###CANADA

prov_pop <- read.csv("prov_pop.csv")
prov_pop <- prov_pop[prov_pop$CHARACTERISTIC_ID==1 
                     & prov_pop$ALT_GEO_CODE !=  1, c(5, 12)]
colnames(prov_pop) <- c("GEO", "pop")
prov_pop <- merge(prov_pop, prov_abr, by="GEO")
prov_pop$to <- prov_pop$from
prov_pop_from <- data.frame(prov_pop$from, prov_pop$pop)
prov_pop_to <- data.frame(prov_pop$to, prov_pop$pop)
colnames(prov_pop_from) <- c("from","from_pop")
colnames(prov_pop_to) <- c("to","to_pop")

pop_from <- rbind(st_pop_from,prov_pop_from)
pop_to <- rbind(st_pop_to,prov_pop_to)
```
Pull everything together to form the us_ca data frame used in analysis
```{r}
#PULL TOGETHER can_exports, can_imports, geoframe, populations, and GDPs
us_ca <- rbind(can_imports, can_exports)
us_ca <- merge(us_ca, geoframe, by = "fttag")
us_ca <- merge(us_ca, gdp_f, by = "from")
us_ca <- merge(us_ca, gdp_t, by = "to")
us_ca <- us_ca[,c(2,1,7,8,5,6,4)]
us_ca <- us_ca <- merge(us_ca, pop_from, by = "from")
us_ca <- us_ca <- merge(us_ca, pop_to, by = "to")
us_ca <- us_ca[us_ca$value != 0,]
us_ca <- us_ca[us_ca$to != "NU" & us_ca$to != "NT" & us_ca$to != "YT" &
                 us_ca$from != "NU" & us_ca$from != "NT" & us_ca$from != "YT",]
```

The completed us_ca data frame is also also available for download on GitHub [@local_bias_dataset].

# Empirical Model

$$ln(\hat{X}_{ij})=\beta_0 +
\beta_1ln(Y_{i}) +
\beta_2ln(Y_{j}) +
\beta_3ln(dist_{ij}) +
\beta_4\delta_{ij} +
ln(\varepsilon_{ij})
$$ Where $log(\hat{X}_{ij})$ is the estimated imports, $Y_{i}$ is the GDP of the exporting province or state, $Y_{j}$ is the GDP of the importing province, $dist_{ij}$ is the distance in kilometers from each province or states population center, and $\delta_{ij}$ is a dummy variable for whether the trade crosses an international border.

*Note that the 5th regression in the summary statistics uses population in lieu of GDP.*

I used $log-log$ regression as there are extreme variances in the data where states with exceptionally high GDP's such as Texas, while being one of the most distant states from the Canadian border still has a significant amount of exports. Using logarithms stabilizes this effect.



# Results

## Regression

This code chunk runs the regression using the fixest::feols() function [@fixest].
```{r}

#REGRESSION

coefnames <- c("Intercept","From GDP", "To GDP", "Distance (km)", "Domestic Dummy" )

reg1 <- feols(log(value)
           ~ log(from_gdp)
           + log(to_gdp)
           + log(km),
           data = us_ca,
           vcov = "hetero",
           subset = us_ca$domestic==1)

names(reg1$coefficients) <- coefnames[1:4]

reg2 <- feols(log(value)
           ~ log(from_gdp)
           + log(to_gdp) 
           + log(km) 
           + domestic, 
           data=us_ca,
           vcov = "hetero")

names(reg2$coefficients) <- coefnames

reg3 <- feols(log(value)
           ~ log(from_gdp)
           + log(to_gdp) 
           + log(km) 
           + domestic, 
           data=us_ca,
           vcov = "hetero", 
           subset=us_ca$from_gdp > 10^4 & us_ca$to_gdp > 10^4)

names(reg3$coefficients) <- coefnames

reg4 <- feols(log(value)
           ~ log(from_gdp)
           + log(to_gdp) 
           + log(km) 
           + domestic, 
           data=us_ca,
           vcov = "hetero",
           weights = us_ca$from_gdp + us_ca$to_gdp)

names(reg4$coefficients) <- coefnames

reg5 <- feols(log(value)
           ~ log(from_pop)
           + log(to_pop) 
           + log(km) 
           + domestic, 
           data=us_ca,
           vcov = "hetero")

names(reg5$coefficients) <- coefnames

reg6 <- feols(log(value)
           ~ log(from_gdp)
           + log(to_gdp) 
           + log(km), 
           data=us_ca,
           vcov = "hetero")

names(reg6$coefficients) <- coefnames[1:4]


regz <- list(reg1, 
             reg2, 
             reg3, 
             reg4, 
             reg5, 
             reg6)

```

A simple scatter plot of distance vs the natural logarithm of imports.
```{r}
#PLOT
plot ((us_ca$km), log(us_ca$value),
      pch = 20,
      cex = 1,
      main = "Distance vs Total Goods Imports",
      xlab = "Distance (km)",
      ylab = "log(Goods Imports)",
      col = alpha(us_ca$domestic+2,0.5),
      las = 1
      )
legend("topright",
       pch = 20,
       bty = "n",
       cex = 0.75,
       horiz = FALSE,
       legend = c("International", "Interprovincial"),
       col = c(2, 3))


title <- "US Canada Trade Data"
frmla <- (`Imports` = value) +
  (`Distance (km)` = km) + 
  (`Export GDP` = from_gdp) +
  (`Import GDP` = to_gdp) ~ 
  (`N` = length) + 
  Mean + 
  (`St. Dev.` = sd) + 
  (`Min` = min) + 
  (`Max` = max)
frmlalog <- (`Imports` = log(value)) +
  (`Distance (km)` = log(km)) + 
  (`Export GDP` = log(from_gdp)) +
  (`Import GDP` = log(to_gdp)) ~ 
  (`N` = length) + 
  Mean + 
  (`St. Dev.` = sd) + 
  (`Min` = min) + 
  (`Max` = max)


```

## Data tables
```{r}
#Output tables
datasummary(frmla, 
            data = us_ca, 
            title = paste(title, "- Summary Statistics"),
            fmt = fmt_significant(2))
datasummary(frmlalog, 
            data = us_ca, 
            title = paste(title, "- Summary Statistics - log"), 
            fmt = fmt_significant(2))
modelsummary(regz, 
             data = us_ca, 
             title = paste(title, "- Regression"),
             fmt = fmt_significant(3),
             statistic = c("SE = {std.error}", 
                           "t = {statistic}",
                           "p = {p.value}"),
             gof_map = c("nobs", "r.squared", "vcov.type"))
             
```

There are six variations of the regresson:\
1. Canada Only \
2. Canada and USA \
3. Canada and USA with GDP greater that $10 billion \
4. Canada and USA weighted by GDP \
5. Canada and USA with population in lieu of GDP \
6. Canada and USA using the naïve gravity model\

## Discussion and Interpretation

For brevity, I will interpret the second variation of the regression: Canada and USA with no other modifications.

$\beta_0$ : Intercept offers nothing meaningful to interpret. \

$\beta_1$ : GDP of exporting province or state: 

A $1\%$ increase in the exporter's GDP will result in a $1.196\%$ increase in imports for the importing province from the given exporter.\

$\beta_2$ : GDP of importing province or state:\

A $1\%$ increase in the importer's GDP will result in a $1.694\%$ increase in imports for that province from a given exporter. \

$\beta_3$ : Distance in kilometers:\

A $1\%$ increase in the distance between the provinces/states from each other will result in a $1.68\%$ decrease in the imports for the receiving province from a given exporter. \

$\beta_4$ : Dummy binary variable for whether an international border exists between the importer and exporter. Interprovincial trade has a value of 1, while international trade has a value of 0. \

$\{e^{\beta_4}-1=\%\Delta X_{ij} : \beta_4 = 4.34\} \approx 7570\%$

This suggests that a province's imports will be $7570\%$ higher from another Canadian province than from a US State, ceteris paribus. \

We can *strongly* reject the null hypothesis for all covariates, including the effect of the international border, with $p < 0.001$. In @RN68 $\beta_4=3.09$ leading to domestic trade having an advantage by a factor of 22 for regression \#2. Here $\beta_4=4.34$ leading to an advantage by a factor of *75*.

Standard errors in all cases are robust to heteroscedasticty.

# Conclusion

It appears that NAFTA has not simply had a muted effect on trade between the U.S. and Canada. Rather, interprovincial trade within Canada has an even greater advantage over trade with the U.S. than it did back in 1988. Simply put, the effect of the international border is even stronger than it was before NAFTA was ratified. 

Notably, total Canadian imports from the United States was $\$74.5 B$ in 1989 with a GDP of $\$567.21 B$, a ratio of $13.2\%$. In 2019, however, the imports were $\$230 B$ with a GDP of $\$1.73 T$ a ratio of $13.3\%$ [@tradingeconomics_canada_imports]. Therefore, this model should be interpreted to mean that Canadian imports from the U.S. have waned. As a percentage of GDP they have remained virtually unchanged. The data also indicates that the most active trading partners in the sample are, in fact, the Canadian province of Ontario and the U.S. State of Michigan [@local_bias_dataset]. 

These results indicate that while U.S.-Canadian trade is very strong, if the international border had no effect and the naïve gravity model held, trade would be much stronger. The results also highlight an omitted variable bias. The naïve gravity model's coefficients $\{\beta_1,\beta_2, \beta_3\}$ also hold up with $p<0.001$ albeit with greater variance with the lowest $R^2$ all six tests. 

# GitHub Repository and e-Portfolio

The entire project including all downloaded *.csv files are available on [GitHub](https://github.com/dasneddon/local_bias). [@dasneddon2024localbias].

Alternatively, the repository can be cloned via CLI:

```{bash}
#| eval: false 
#| echo: true
#| output: false

git clone https://github.com/dasneddon/local_bias.git
```

The requirements for this assignment also include an e-Portfolio which can be found [here](https://sites.google.com/odu.edu/david-sneddon/).










